name: Run SLURM Jobs

permissions:
  contents: write

on:
  push:
    paths:
      - "input/**"

jobs:
  run-slurm:
    runs-on: self-hosted

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Prepare working and output directories
        run: |
          set -euo pipefail
          mkdir -p output
          export SLURM_TMP_BASE="/tmp/slurm_jobs_${GITHUB_RUN_ID}"
          mkdir -p "$SLURM_TMP_BASE"
          echo "SLURM_TMP_BASE=$SLURM_TMP_BASE" >> "$GITHUB_ENV"

      - name: Copy nested job folders to SLURM temp dir
        run: |
          set -euo pipefail
          shopt -s nullglob

          copied_any=0
          for jobdir in input/{HPL,SST,ECE}/{Ayush,Beno,Daniel,John,Nicholas,Sithum,Will}/*; do
            [ -d "$jobdir" ] || continue
            relpath="${jobdir#input/}"
            dest="${SLURM_TMP_BASE}/${relpath}"
            mkdir -p "$dest"
            # Copy including hidden files
            cp -r "$jobdir"/. "$dest"/ || true
            echo "Copied $jobdir -> $dest"
            copied_any=1
          done

          if [ "$copied_any" -eq 0 ]; then
            echo "No job directories found under input/{HPL,SST,ECE}/{Ayush,Beno,Daniel,John,Nicholas,Sithum,Will}/*"
          fi

          echo "Directory structure in temp dir:"
          command -v tree >/dev/null && tree "$SLURM_TMP_BASE" || ls -R "$SLURM_TMP_BASE"

      - name: Discover SLURM nodes
        run: |
          set -euo pipefail
          # Collect nodes in useful states (exclude down/drain)
          sinfo -N -h -t idle,alloc,mix,comp -o "%n" | sort -u > nodes.txt
          node_count="$(wc -l < nodes.txt | tr -d ' ')"
          echo "Found $node_count nodes:"
          cat nodes.txt || true
          echo "NODES_FILE=$(pwd)/nodes.txt" >> "$GITHUB_ENV"

      - name: Distribute job folders to all cluster nodes
        run: |
          set -euo pipefail
          nodes_file="${NODES_FILE:-nodes.txt}"
          remote_base="${SLURM_TMP_BASE}"
          : "${DISTRIBUTION_CONCURRENCY:=8}"

          if [ ! -s "$nodes_file" ]; then
            echo "No nodes found; skipping distribution."
            exit 0
          fi

          echo "Distributing $SLURM_TMP_BASE to all nodes..."
          failures=0
          running=0

          copy_to_node() {
            local node="$1"
            echo "[${node}] creating $remote_base"
            if ! ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
              "$node" "mkdir -p '$remote_base'"
            then
              echo "[${node}] mkdir failed"
              return 1
            fi

            if ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
              "$node" 'command -v rsync >/dev/null 2>&1'
            then
              echo "[${node}] rsync -> $remote_base"
              rsync -a --delete \
                -e "ssh -o BatchMode=yes -o StrictHostKeyChecking=no" \
                "$SLURM_TMP_BASE"/ "$node:$remote_base"/
            else
              echo "[${node}] tar stream -> $remote_base"
              tar -C "$SLURM_TMP_BASE" -cf - . \
                | ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
                  "$node" "tar -C '$remote_base' -xf -"
            fi
          }

          while IFS= read -r node; do
            [ -n "$node" ] || continue
            (
              if ! copy_to_node "$node"; then
                echo "[${node}] distribution failed"
                exit 1
              fi
            ) &
            running=$((running + 1))
            if [ "$running" -ge "$DISTRIBUTION_CONCURRENCY" ]; then
              if ! wait -n; then
                failures=$((failures + 1))
              fi
              running=$((running - 1))
            fi
          done < "$nodes_file"

          # Wait for remaining background jobs
          while [ "$running" -gt 0 ]; do
            if ! wait -n; then
              failures=$((failures + 1))
            fi
            running=$((running - 1))
          done

          if [ "$failures" -ne 0 ]; then
            echo "Distribution encountered $failures failures."
            exit 1
          fi
          echo "Distribution completed successfully."

      - name: Submit jobs to SLURM (.sh files in each job folder)
        run: |
          set -euo pipefail
          shopt -s nullglob

          : > joblist.txt
          any_submitted=0

          for jobdir in "${SLURM_TMP_BASE}"/{HPL,SST,ECE}/{Ayush,Beno,Daniel,John,Nicholas,Sithum,Will}/*; do
            [ -d "$jobdir" ] || continue
            jobrel="${jobdir#${SLURM_TMP_BASE}/}"

            scripts_found=0
            for script in "$jobdir"/*.sh; do
              [ -f "$script" ] || continue
              scripts_found=1
              fname="$(basename "$script")"
              echo "Submitting $fname from $jobrel..."
              jobid="$(sbatch --parsable \
                --chdir="$jobdir" \
                --output="${jobdir}/${fname}-%j.out" \
                "$script")"
              echo "${jobrel}|${fname}:$jobid" >> joblist.txt
              any_submitted=1
            done

            if [ "$scripts_found" -eq 0 ]; then
              echo "No .sh scripts found in $jobrel; skipping." >&2
            fi
          done

          if [ "$any_submitted" -eq 0 ]; then
            echo "No jobs submitted. Nothing to do."
          else
            echo "Submitted jobs:"
            cat joblist.txt || true
          fi

      - name: Wait for jobs to finish
        run: |
          set -euo pipefail

          if [ ! -s joblist.txt ]; then
            echo "No jobs to wait for."
            exit 0
          fi

          echo "Waiting for SLURM jobs to complete..."
          while read -r line; do
            [ -n "$line" ] || continue
            jobid="${line##*:}"
            while squeue -j "$jobid" | grep -q "$jobid"; do
              sleep 10
            done
          done < joblist.txt

      - name: Check job exit codes and mark completed job dirs
        run: |
          set -euo pipefail

          if [ ! -s joblist.txt ]; then
            echo "No jobs submitted; skipping checks."
            : > completed_dirs.txt
            exit 0
          fi

          echo "Checking SLURM job exit codes..."
          failed_any=0

          # Build list of all job directories involved (relative to input/)
          cut -d: -f1 joblist.txt | awk -F'|' '{print $1}' | sort -u \
            > jobdirs_all.txt

          : > failed_dirs.txt

          while read -r line; do
            [ -n "$line" ] || continue
            entry="${line%%:*}"   # jobrel|script
            jobid="${line##*:}"
            jobrel="${entry%%|*}"
            script="${entry##*|}"

            state="$(scontrol show job "$jobid" \
              | awk -F= '/JobState=/{print $2}' | awk '{print $1}')"
            exitcode="$(scontrol show job "$jobid" \
              | awk -F= '/ExitCode=/{print $2}' | awk '{print $1}')"

            echo "Job $jobid ($script) in $jobrel finished with state=$state exitcode=$exitcode"
            if [[ "$state" != "COMPLETED" ]]; then
              failed_any=1
              echo "$jobrel" >> failed_dirs.txt
            fi
          done < joblist.txt

          sort -u failed_dirs.txt > failed_dirs_sorted.txt || true
          sort -u jobdirs_all.txt > jobdirs_all_sorted.txt || true
          touch failed_dirs_sorted.txt jobdirs_all_sorted.txt

          # Job directories where all submitted scripts completed successfully
          comm -23 jobdirs_all_sorted.txt failed_dirs_sorted.txt \
            > completed_dirs.txt || true

          echo "Job directories with all jobs completed successfully:"
          cat completed_dirs.txt || echo "(none)"

          if [[ $failed_any -ne 0 ]]; then
            echo "One or more jobs failed at the Slurm level."
            exit 1
          fi

      - name: Gather output files from all nodes
        run: |
          set -euo pipefail
          shopt -s nullglob
          nodes_file="${NODES_FILE:-nodes.txt}"

          mkdir -p output

          if [ ! -s "$nodes_file" ]; then
            echo "No nodes found; skipping output collection."
            exit 0
          fi

          echo "Collecting outputs from all nodes..."
          failures=0
          running=0
          : "${GATHER_CONCURRENCY:=8}"

          fetch_from_node() {
            local node="$1"
            # Skip node if remote dir doesn't exist
            if ! ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
              "$node" "test -d '$SLURM_TMP_BASE'"
            then
              echo "[${node}] $SLURM_TMP_BASE not found; skipping."
              return 0
            fi

            if ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
              "$node" 'command -v rsync >/dev/null 2>&1'
            then
              echo "[${node}] rsync -> output/"
              rsync -a --ignore-errors \
                -e "ssh -o BatchMode=yes -o StrictHostKeyChecking=no" \
                "$node:$SLURM_TMP_BASE"/ output/
            else
              echo "[${node}] tar stream -> output/"
              ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
                "$node" "tar -C '$SLURM_TMP_BASE' -cf - ." \
                | tar -C output -xf -
            fi
          }

          while IFS= read -r node; do
            [ -n "$node" ] || continue
            (
              if ! fetch_from_node "$node"; then
                echo "[${node}] fetch failed"
                exit 1
              fi
            ) &
            running=$((running + 1))
            if [ "$running" -ge "$GATHER_CONCURRENCY" ]; then
              if ! wait -n; then
                failures=$((failures + 1))
              fi
              running=$((running - 1))
            fi
          done < "$nodes_file"

          while [ "$running" -gt 0 ]; do
            if ! wait -n; then
              failures=$((failures + 1))
            fi
            running=$((running - 1))
          done

          if [ "$failures" -ne 0 ]; then
            echo "Output collection encountered $failures failures."
            exit 1
          fi

          # Clean up local staging after collection
          rm -rf "${SLURM_TMP_BASE}"

      - name: Cleanup remote staging on all nodes
        run: |
          set -euo pipefail
          nodes_file="${NODES_FILE:-nodes.txt}"
          if [ ! -s "$nodes_file" ]; then
            echo "No nodes found; skipping remote cleanup."
            exit 0
          fi

          echo "Removing $SLURM_TMP_BASE from all nodes..."
          pdsh_ok=0
          if command -v pdsh >/dev/null 2>&1; then
            pdsh_ok=1
          fi

          if [ "$pdsh_ok" -eq 1 ]; then
            pdsh -R ssh -w ^"$nodes_file" "rm -rf '$SLURM_TMP_BASE'" || true
          else
            while IFS= read -r node; do
              [ -n "$node" ] || continue
              ssh -o BatchMode=yes -o StrictHostKeyChecking=no \
                "$node" "rm -rf '$SLURM_TMP_BASE'" || true
            done < "$nodes_file"
          fi

      - name: Commit output and remove completed inputs
        run: |
          set -euo pipefail

          # Remove only job directories (HPL/SST/ECE)/(Ayush,Beno,Daniel,John,Nicholas,Sithum,Will)/* that completed
          if [ -s completed_dirs.txt ]; then
            echo "Removing input directories for completed jobs..."
            while read -r d; do
              [ -n "$d" ] || continue
              if [ -d "input/$d" ]; then
                rm -rf "input/$d"
                echo "Deleted input/$d"
              fi
            done < completed_dirs.txt
          else
            echo "No completed job directories to remove."
          fi

          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git remote set-url origin \
            "https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git"

          # Stage outputs and input deletions
          git add -A output/ input/
          git commit -m "Add SLURM job output and remove completed inputs from run ${GITHUB_RUN_ID} [skip ci]" \
            || echo "No changes to commit"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload output as artifact
        uses: actions/upload-artifact@v4
        with:
          name: slurm-job-output
          path: output/