{
  "id": "HPL/Ayush/AOCL ",
  "suite": "HPL",
  "group": "Ayush",
  "run": "AOCL ",
  "dat": {
    "raw": "HPLinpack benchmark input file  \nOptimized for 4-node AMD EPYC 7313 cluster  \nHPL.out      output file name (if any)  \n6            device out (6=stdout, 7=stderr, file)  \n1            # of problems sizes (N)  \n430080       Ns (matrix size N)  \n1            # of NBs  \n240          NBs (block size)  \n0            PMAP process mapping (0=Row-,1=Column-major)  \n1            # of process grids (P x Q)  \n8            Ps (process rows)  \n16           Qs (process cols)  \n16.0         threshold (residual check)  \n1            # of panel factorizations to try  \n1            PFACT (0=Left, 1=Crout, 2=Right)  \n1            # of recursive stopping criteria  \n4            NBMIN (min block size)  \n1            # of panels in recursion  \n2            NDIV (number of sub-panels)  \n1            # of recursive panel factorizations to try  \n1            RFACT (0=Left, 1=Crout, 2=Right)  \n1            # of broadcast methods to try  \n2            BCAST (0=1rg,1=1rM,2=2rg,3=2rM,4=Long,5=LnM)  \n1            # of lookahead depths to try  \n0            DEPTH (lookahead depth)  \n2            SWAP (0=bin-exch,1=long,2=mix)  \n64           swapping threshold  \n0            L1 in (0=transposed,1=no-transposed) form  \n0            U  in (0=transposed,1=no-transposed) form  \n1            Equilibration (0=no,1=yes)  \n8            memory alignment in double (> 0)\n",
    "parsed": {
      "header": [
        "HPLinpack benchmark input file",
        "Optimized for 4-node AMD EPYC 7313 cluster"
      ],
      "outputFilename": "HPL.out",
      "deviceOut": 6,
      "numProblemSizes": 1,
      "Ns": [
        430080
      ],
      "numNBs": 1,
      "NBs": [
        240
      ],
      "pmap": 0,
      "numGrids": 1,
      "Ps": [
        8
      ],
      "Qs": [
        16
      ],
      "threshold": 16,
      "numPFACT": 1,
      "PFACTs": [],
      "numNBMIN": null,
      "NBMINs": [],
      "numPanelsInRecursion": 1,
      "NDIVs": [],
      "numRFACT": 1,
      "RFACTs": [],
      "numBCAST": 1,
      "BCASTs": [],
      "numDEPTH": 1,
      "DEPTHs": [],
      "swapMode": 2,
      "swapThreshold": 64,
      "L1": 0,
      "U": 0,
      "equilibration": 1,
      "memoryAlignment": 8
    },
    "path": "/raw/HPL/Ayush/AOCL /HPL.dat"
  },
  "job": {
    "filename": "run.sh",
    "raw": "#!/bin/bash\n#SBATCH --job-name=hpl-aocl\n#SBATCH --nodes=4\n#SBATCH --ntasks=128\n#SBATCH --ntasks-per-node=32\n#SBATCH --cpus-per-task=1\n#SBATCH --time=12:00:00\n#SBATCH --nodelist=node1,node2,node3,node4\n\nsource ~/.bashrc\nexport HPCX_HOME=/home/hpc/hpcx/hpcx-v2.24-gcc-doca_ofed-ubuntu24.04-cuda13-x86_64\nsource \"$HPCX_HOME/hpcx-init.sh\"\nhpcx_load\n\n# === AOCL BLIS ===\nexport AOCLROOT=/opt/AMD/aocl-5.1.0/5.1.0/gcc\n\n# Build LD_LIBRARY_PATH once (highest priority first)\nexport LD_LIBRARY_PATH=\"$HPCX_HOME/ucx/lib:$HPCX_HOME/ompi/lib:$AOCLROOT/lib_LP64:/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}\"\n\n# CPU-only HPL: avoid CUDA/NCCL/NVSHMEM libs and LD_PRELOADs\nunset LD_PRELOAD\n\n# OpenMP/BLIS threading\nexport OMP_NUM_THREADS=1\nexport OMP_PROC_BIND=true\nexport OMP_PLACES=cores\nexport BLIS_NUM_THREADS=$OMP_NUM_THREADS\n\n# === UCX selection (you verified mlx5_0:1 exists everywhere) ===\nexport UCX_NET_DEVICES=mlx5_0:1\nexport UCX_TLS=rc_mlx5,sm,self\nexport UCX_RNDV_SCHEME=put_zcopy\nexport UCX_IB_PCI_RELAXED_ORDERING=on\n# If you are on RoCE and need a specific GID (common on VLANs), uncomment:\n\n\n# === Open MPI knobs ===\nexport OMPI_MCA_pml=ucx\nexport OMPI_MCA_btl=^vader,tcp,openib,uct\n\n# Disable HCOLL & UCC (theyâ€™re causing the coll_hcoll init errors)\nexport OMPI_MCA_coll_hcoll_enable=0\nexport OMPI_MCA_coll_ucc_enable=0\n\n# === PMIx/OOB control plane interface pinning ===\n# Use your routable mgmt/LAN NIC (replace eno1np0 if different)\nexport OMPI_MCA_oob_tcp_if_include=eno1np0\nexport PMIX_MCA_ptl_tcp_if_include=eno1np0\n\n# Helpful logging while debugging:\n# export UCX_LOG_LEVEL=info\n# export OMPI_MCA_btl_base_verbose=0\n\n# Limits\nulimit -l unlimited\nulimit -n 65536\n\n# Run HPL\nmpirun ./xhpl",
    "sbatch": {
      "job-name": "hpl-aocl",
      "nodes": 4,
      "ntasks": 128,
      "ntasks-per-node": 32,
      "cpus-per-task": 1,
      "time": "12:00:00",
      "nodelist": "node1,node2,node3,node4"
    },
    "path": "/raw/HPL/Ayush/AOCL /run.sh"
  },
  "out": {
    "path": "/raw/HPL/Ayush/AOCL /run.sh-1344.out",
    "runs": [],
    "summary": {
      "testsTotal": null,
      "testsPassed": null,
      "testsFailed": null,
      "testsSkipped": null
    }
  },
  "err": {
    "path": "/raw/HPL/Ayush/AOCL /run.sh-1344.err",
    "size": 59541
  },
  "best": null
}