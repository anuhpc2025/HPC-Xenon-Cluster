{
  "id": "HPL_NVIDIA/Daniel/test_4_2",
  "suite": "HPL_NVIDIA",
  "group": "Daniel",
  "run": "test_4_2",
  "dat": {
    "raw": "HPLinpack benchmark input file\nInnovative Computing Laboratory, University of Tennessee\nHPL.out      output file name (if any)\n6            device out (6=stdout,7=stderr,file)\n1            # of problems sizes (N)\n190000       Ns\n1            # of NBs\n1024          NBs\n1            PMAP process mapping (0=Row-,1=Column-major)\n1            # of process grids (P x Q)\n4            Ps\n2            Qs\n16.0         threshold\n1            # of panel fact\n0 1 2        PFACTs (0=left, 1=Crout, 2=Right)\n1            # of recursive stopping criterium\n2 8          NBMINs (>= 1)\n1            # of panels in recursion\n2            NDIVs\n1            # of recursive panel fact.\n0 1 2        RFACTs (0=left, 1=Crout, 2=Right)\n1            # of broadcast\n3 2          BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)\n1            # of lookahead depth\n1 0          DEPTHs (>=0)\n1            SWAP (0=bin-exch,1=long,2=mix)\n192          swapping threshold\n1            L1 in (0=transposed,1=no-transposed) form\n0            U  in (0=transposed,1=no-transposed) form\n0            Equilibration (0=no,1=yes)\n8            memory alignment in double (> 0)",
    "parsed": {
      "header": [
        "HPLinpack benchmark input file",
        "Innovative Computing Laboratory, University of Tennessee"
      ],
      "outputFilename": "HPL.out",
      "deviceOut": 6,
      "numProblemSizes": 1,
      "Ns": [
        190000
      ],
      "numNBs": 1,
      "NBs": [
        1024
      ],
      "pmap": 1,
      "numGrids": 1,
      "Ps": [
        4
      ],
      "Qs": [
        2
      ],
      "threshold": 16,
      "numPFACT": 1,
      "PFACTs": [
        0,
        1,
        2,
        0,
        1,
        2
      ],
      "numNBMIN": 1,
      "NBMINs": [
        2,
        8,
        1
      ],
      "numPanelsInRecursion": 1,
      "NDIVs": [
        2
      ],
      "numRFACT": 1,
      "RFACTs": [
        0,
        1,
        2,
        0,
        1,
        2
      ],
      "numBCAST": 1,
      "BCASTs": [
        3,
        2,
        0,
        1,
        1,
        1,
        2,
        2,
        3,
        2,
        4,
        5
      ],
      "numDEPTH": 1,
      "DEPTHs": [
        1,
        0,
        0
      ],
      "swapMode": 1,
      "swapThreshold": 192,
      "L1": 1,
      "U": 0,
      "equilibration": 0,
      "memoryAlignment": 8
    },
    "path": "/raw/HPL_NVIDIA/Daniel/test_4_2/HPL.dat"
  },
  "job": {
    "filename": "job.sh",
    "raw": "#!/bin/bash\n#SBATCH --job-name=hpl-test       # Job name\n#SBATCH --ntasks=8                # Total MPI tasks - 4 x 4\n#SBATCH --ntasks-per-node=4       # balance tasks across nodes - 1 per gpu\n#SBATCH --time=01:00:00           # Time limit hh:mm:ss\n#SBATCH --nodes=2                 #\n#SBATCH --nodelist=node1,node2    # nodes 1 and 2 are the only ones with hpcx for now\n\n# Load hpcx module - and everything else we need for that matter\nsource ~/.bashrc\n\n# hpc-x\nexport HPCX_HOME=/home/hpc/hpcx/hpcx-v2.24-gcc-doca_ofed-ubuntu24.04-cuda13-x86_64\nexport LD_LIBRARY_PATH=$HPCX_HOME/ucx/lib:$HPCX_HOME/ompi/lib:$LD_LIBRARY_PATH\nexport PATH=$HPCX_HOME/ompi/bin:$PATH\nsource $HPCX_HOME/hpcx-init.sh\nhpcx_load\n\n# nvidia\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\nexport HPL_USE_GPU=1\nexport HPL_CUDA_MODE=1\nexport LD_LIBRARY_PATH=/opt/nvidia/nvidia_hpc_benchmarks_openmpi/lib/omp:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:/opt/nvidia/nvidia_hpc_benchmarks_openmpi/lib/nccl:/opt/nvidia/nvidia_hpc_benchmarks_openmpi/lib:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/nvshmem/12:$LD_LIBRARY_PATH\n\n#testing\nulimit -l unlimited\nulimit -n 65536\n\n# Run the MPI program\nmpirun ./xhpl-nvidia",
    "sbatch": {
      "job-name": "hpl-test       # Job name",
      "ntasks": null,
      "ntasks-per-node": null,
      "time": "01:00:00           # Time limit hh:mm:ss",
      "nodes": null,
      "nodelist": "node1,node2    # nodes 1 and 2 are the only ones with hpcx for now"
    },
    "path": "/raw/HPL_NVIDIA/Daniel/test_4_2/job.sh"
  },
  "out": {
    "path": "/raw/HPL_NVIDIA/Daniel/test_4_2/job.sh-307.out",
    "runs": [
      {
        "tv": "WC0",
        "N": 189440,
        "NB": 1024,
        "P": 4,
        "Q": 2,
        "timeSec": 55.97,
        "gflops": 80980,
        "gflopsPerGpu": 10120
      }
    ],
    "summary": {
      "testsTotal": 1,
      "testsPassed": 1,
      "testsFailed": 0,
      "testsSkipped": 0
    },
    "deviceInfo": {
      "peakClockMHz": 1410,
      "smVersion": 80,
      "numSms": 108
    },
    "memInfo": {
      "DEVICE": {
        "System": {
          "minGiB": 2.98579,
          "maxGiB": 2.98579,
          "avgGiB": 2.98579
        },
        "HPL buffers": {
          "minGiB": 37.67062,
          "maxGiB": 38.75657,
          "avgGiB": 38.03097
        },
        "Used": {
          "minGiB": 40.65641,
          "maxGiB": 41.74236,
          "avgGiB": 41.01677
        },
        "Total": {
          "minGiB": 40,
          "maxGiB": 40,
          "avgGiB": 40
        }
      },
      "HOST": {
        "HPL buffers": {
          "minGiB": 0.00044,
          "maxGiB": 0.00044,
          "avgGiB": 0.00044
        }
      }
    },
    "traces": [
      "[HPL TRACE] cuda_nvshmem_init: max=1.0786 (2) min=1.0785 (5)",
      "[HPL TRACE] ncclCommInitRank: max=0.0954 (3) min=0.0930 (1)",
      "[HPL TRACE] cugetrfs_mp_init: max=0.2146 (0) min=0.2145 (6)",
      "[HPL TRACE] HPL_pdmatgen_gpu: max=0.0304 (5) min=0.0303 (2)"
    ],
    "startTime": "Thu Sep  4 11:31:04 2025",
    "endTime": "Thu Sep  4 11:32:00 2025",
    "residual": 0.000395085514,
    "residualPassed": true
  },
  "err": null,
  "best": {
    "gflops": 80980,
    "N": 189440,
    "NB": 1024,
    "timeSec": 55.97
  }
}